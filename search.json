[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mariamaladsani.github.io",
    "section": "",
    "text": "Master’s student in UT Dallas’ Applied Cognition and Neuroscience program.\nContact: mariam.aladsani[at]utdallas.com"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am currently a master’s student at the University of Texas at Dallas’ Applied Cognition and Neuroscience program. In the spring of 2022, I graduated from Boston University with a BA in Psychology and a double minor in Philosophy and Comparative Literature. During my undergraduate career, I partook in research involving molecular neuroscience and clinical neuropsychology. In Dr. Ryan Logan’s lab in the Boston University School of Medicine, I worked on a project that investigated the role of circadian rhythms in opiod-seeking, craving, and relapse. At the Manoach Lab at Massachusetts General Hospital, I worked on a study investigating the relationship between memory consolidation and sleep in schizophrenic patients using EEG, MRI, and MEG, as well as neuropsychological assessments.\nDuring my graduate studies I am hoping to bridge my interests in both molecular neuroscience and neuropsychology. I am interested in how social and environmental factors in early life can impact and/or impair cognitive functions like memory later on in life. Overall, I aspire to be a well-rounded neuroscientist by conducting research that draws from different disciplines and methods.\nYou can find my CV here.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#assignment-1",
    "href": "index.html#assignment-1",
    "title": "mariamaladsani.github.io",
    "section": "Assignment 1",
    "text": "Assignment 1\nAnalysis of survey:\nQ2a. The survey is structured in a way where questions concerning the content is presented before the demographic information is asked.\nQ2b. The questionnaire is composed of an array of different questions, that range from binary answers like yes or no to Likert scales questions. The survey also includes questions that have logic, this always questions to be followed up or skipped based on questions with binary responses.\nQ2c. The questions are ordered so that the survey questions are presented first and the demographics are placed last.\nQ7. One way to improve a respondent’s experience is to break up the survey into sections to maintain cohesion and synchronicity throughout the survey.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#website-httpsmariamaladsani.github.io",
    "href": "index.html#website-httpsmariamaladsani.github.io",
    "title": "mariamaladsani.github.io",
    "section": "[Website] https://mariamaladsani.github.io",
    "text": "[Website] https://mariamaladsani.github.io"
  },
  {
    "objectID": "index.html#assignment-2",
    "href": "index.html#assignment-2",
    "title": "mariamaladsani.github.io",
    "section": "Assignment 2",
    "text": "Assignment 2\nI examined that number of searches for ‘Trump’ following the announcement of his election on June 6th 2015 for the 2016 US Election, up until 2023. I also examined the searches for ‘Biden’ following the same dates as my previous search.\nIn October and November 2016 there was a spike in searches for ‘Trump,’ coinciding to the election date. There was another sharp peak in ‘Trump,’ searches in October and November 2020. The search item ‘Biden’ was at its peak between the years of 2015 and 2023 in November 2020 during the election. Following the November 2020 election there was still more searches for ‘Biden,’ compared years 2015-early 2019, but not as frequent as the years of 2019 and 2020. The term ‘Election’ has a varied number of searches over time. The highest peaks being November 2016 and November 2020. There was a sharp dip of searches after January 2021, with some peaks in the searches in early to mid 2023.\nAll of the searches were exclusive to Google trends in the United States."
  },
  {
    "objectID": "assign01.html",
    "href": "assign01.html",
    "title": "assign01",
    "section": "",
    "text": "Analysis of survey:\nQ2a. The survey is structured in a way where questions concerning the content is presented before the demographic information is asked.\nQ2b. The questionnaire is composed of an array of different questions, that range from binary answers like yes or no to Likert scales questions. The survey also includes questions that have logic, this always questions to be followed up or skipped based on questions with binary responses.\nQ2c. The questions are ordered so that the survey questions are presented first and the demographics are placed last.\nQ7. One way to improve a respondent’s experience is to break up the survey into sections to maintain cohesion and synchronicity throughout the survey."
  },
  {
    "objectID": "assign01.html#assignment-1",
    "href": "assign01.html#assignment-1",
    "title": "assign01",
    "section": "",
    "text": "Analysis of survey:\nQ2a. The survey is structured in a way where questions concerning the content is presented before the demographic information is asked.\nQ2b. The questionnaire is composed of an array of different questions, that range from binary answers like yes or no to Likert scales questions. The survey also includes questions that have logic, this always questions to be followed up or skipped based on questions with binary responses.\nQ2c. The questions are ordered so that the survey questions are presented first and the demographics are placed last.\nQ7. One way to improve a respondent’s experience is to break up the survey into sections to maintain cohesion and synchronicity throughout the survey."
  },
  {
    "objectID": "assign02.html",
    "href": "assign02.html",
    "title": "assign02",
    "section": "",
    "text": "I examined that number of searches for ‘Trump’ following the announcement of his election on June 6th 2015 for the 2016 US Election, up until 2023. I also examined the searches for ‘Biden’ following the same dates as my previous search.\nIn October and November 2016 there was a spike in searches for ‘Trump,’ coinciding to the election date. There was another sharp peak in ‘Trump,’ searches in October and November 2020. The search item ‘Biden’ was at its peak between the years of 2015 and 2023 in November 2020 during the election. Following the November 2020 election there was still more searches for ‘Biden,’ compared years 2015-early 2019, but not as frequent as the years of 2019 and 2020. The term ‘Election’ has a varied number of searches over time. The highest peaks being November 2016 and November 2020. There was a sharp dip of searches after January 2021, with some peaks in the searches in early to mid 2023.\nAll of the searches were exclusive to Google trends in the United States."
  },
  {
    "objectID": "assign02.html#assignment-2",
    "href": "assign02.html#assignment-2",
    "title": "assign02",
    "section": "",
    "text": "I examined that number of searches for ‘Trump’ following the announcement of his election on June 6th 2015 for the 2016 US Election, up until 2023. I also examined the searches for ‘Biden’ following the same dates as my previous search.\nIn October and November 2016 there was a spike in searches for ‘Trump,’ coinciding to the election date. There was another sharp peak in ‘Trump,’ searches in October and November 2020. The search item ‘Biden’ was at its peak between the years of 2015 and 2023 in November 2020 during the election. Following the November 2020 election there was still more searches for ‘Biden,’ compared years 2015-early 2019, but not as frequent as the years of 2019 and 2020. The term ‘Election’ has a varied number of searches over time. The highest peaks being November 2016 and November 2020. There was a sharp dip of searches after January 2021, with some peaks in the searches in early to mid 2023.\nAll of the searches were exclusive to Google trends in the United States."
  },
  {
    "objectID": "index.html#assignment-3",
    "href": "index.html#assignment-3",
    "title": "mariamaladsani.github.io",
    "section": "Assignment 3",
    "text": "Assignment 3\nIn this assignment we were asked to analyze Biden-Xi summit that took place in November 2021. During this summit, Biden and Xi discussed China’s domestic policies, trade relationships, and security issues regarding the Asian region (Politico). For this assignment, we used the R alongside a Quantenda package to scrape and analyze Twitter data on the day of the summit. The twitter data analyzed displayed activity ranging from interactions, trending hashtags, popular users that were tagged, and prominent rhetoric on the day of the summit.\nThis is the summary of data:\nThe most popular hashtags on that were” #china”,” #joebiden”,” #xinjinping”, and “#america”. Other popular hashtags were “#usa,” “#breakingnews,” and “pray4america.” Quantenda data also pulled other popular hashtags from twitters among the ones not notes above are: “#uyghurgenocide,” “#uyghur,” “#humanrights,” “tibetans,” “taiwan,” “#coronavirus,” and interestingly enough “#fentanyl.” This plot shows how the variety of hashtags were used, and their connection with one another.\n\n\n\n\n\nThe Quantenda data allowed us to look at the 20 top users that were featured on the data matrix. The five top users mentioned were @POTUS, @JoeBiden, @Politico @EnesKanter, and @jendeben. The accompanying plot displays the interaction between various twitter users.\n\n\n\n\n\n\n\n\n\n\nAnother data point was analyzing lexical dispersion of US Presidents from 1953 to 2021. This plot ranged from 1953 when president Eisenhower was in office to current president Joe Biden. There is a lexical dispersion plot aimed to account for the frequency of times that presidents have used the term ‘american,’ in their speeches. In the plots this accounted for by referring to the term ‘relative token index.’ There is a wide variation of frequency among the US presidents, but according to the plot the use of the term does seem to slight increase around 1993 when Clinton was in office.\n\n\n\n\n\nThe second part of the lexical dispersion plot was comparing the frequencies between the words “american,” and “people.” The word “people,” showed less variation among presidents and was used quite frequently among all of them.\n\n\n\n\n\nLastly, we were asked to discuss Wordfish it. Wordfish analyzes positions of documents based on word frequencies. They do so by using a one-dimension scaling model."
  },
  {
    "objectID": "assign03.html",
    "href": "assign03.html",
    "title": "assign03",
    "section": "",
    "text": "In this assignment we were asked to analyze Biden-Xi summit that took place in November 2021. During this summit, Biden and Xi discussed China’s domestic policies, trade relationships, and security issues regarding the Asian region (Politico). For this assignment, we used the R alongside a Quantenda package to scrape and analyze Twitter data on the day of the summit. The twitter data analyzed displayed activity ranging from interactions, trending hashtags, popular users that were tagged, and p\nrominent rhetoric on the day of the summit.\nThis is the summary of data:\nThe most popular hashtags on that were” #china”,” #joebiden”,” #xinjinping”, and “#america”. Other popular hashtags were “#usa,” “#breakingnews,” and “pray4america.” Quantenda data also pulled other popular hashtags from twitters among the ones not notes above are: “#uyghurgenocide,” “#uyghur,” “#humanrights,” “tibetans,” “taiwan,” “#coronavirus,” and interestingly enough “#fentanyl.” This plot shows how the variety of hashtags were used, and their connection with one another.\n\n\n\n\n\nThe Quantenda data allowed us to look at the 20 top users that were featured on the data matrix. The five top users mentioned were @POTUS, @JoeBiden, @Politico @EnesKanter, and @jendeben. The accompanying plot displays the interaction between various twitter users.\n\n\n\n\n\n\n\n\n\n\nAnother data point was analyzing lexical dispersion of US Presidents from 1953 to 2021. This plot ranged from 1953 when president Eisenhower was in office to current president Joe Biden. There is a lexical dispersion plot aimed to account for the frequency of times that presidents have used the term ‘american,’ in their speeches. In the plots this accounted for by referring to the term ‘relative token index.’ There is a wide variation of frequency among the US presidents, but according to the plot the use of the term does seem to slight increase around 1993 when Clinton was in office.\n\n\n\n\n\nThe second part of the lexical dispersion plot was comparing the frequencies between the words “american,” and “people.” The word “people,” showed less variation among presidents and was used quite frequently among all of them.\n\n\n\n\n\nLastly, we were asked to discuss Wordfish it. Wordfish analyzes positions of documents based on word frequencies. They do so by using a one-dimension scaling model."
  },
  {
    "objectID": "assign03.html#assignment-3",
    "href": "assign03.html#assignment-3",
    "title": "assign03",
    "section": "",
    "text": "In this assignment we were asked to analyze Biden-Xi summit that took place in November 2021. During this summit, Biden and Xi discussed China’s domestic policies, trade relationships, and security issues regarding the Asian region (Politico). For this assignment, we used the R alongside a Quantenda package to scrape and analyze Twitter data on the day of the summit. The twitter data analyzed displayed activity ranging from interactions, trending hashtags, popular users that were tagged, and p\nrominent rhetoric on the day of the summit.\nThis is the summary of data:\nThe most popular hashtags on that were” #china”,” #joebiden”,” #xinjinping”, and “#america”. Other popular hashtags were “#usa,” “#breakingnews,” and “pray4america.” Quantenda data also pulled other popular hashtags from twitters among the ones not notes above are: “#uyghurgenocide,” “#uyghur,” “#humanrights,” “tibetans,” “taiwan,” “#coronavirus,” and interestingly enough “#fentanyl.” This plot shows how the variety of hashtags were used, and their connection with one another.\n\n\n\n\n\nThe Quantenda data allowed us to look at the 20 top users that were featured on the data matrix. The five top users mentioned were @POTUS, @JoeBiden, @Politico @EnesKanter, and @jendeben. The accompanying plot displays the interaction between various twitter users.\n\n\n\n\n\n\n\n\n\n\nAnother data point was analyzing lexical dispersion of US Presidents from 1953 to 2021. This plot ranged from 1953 when president Eisenhower was in office to current president Joe Biden. There is a lexical dispersion plot aimed to account for the frequency of times that presidents have used the term ‘american,’ in their speeches. In the plots this accounted for by referring to the term ‘relative token index.’ There is a wide variation of frequency among the US presidents, but according to the plot the use of the term does seem to slight increase around 1993 when Clinton was in office.\n\n\n\n\n\nThe second part of the lexical dispersion plot was comparing the frequencies between the words “american,” and “people.” The word “people,” showed less variation among presidents and was used quite frequently among all of them.\n\n\n\n\n\nLastly, we were asked to discuss Wordfish it. Wordfish analyzes positions of documents based on word frequencies. They do so by using a one-dimension scaling model."
  },
  {
    "objectID": "assign03.html#assignment-3-quantenda",
    "href": "assign03.html#assignment-3-quantenda",
    "title": "assign03",
    "section": "",
    "text": "In this assignment we were asked to analyze Biden-Xi summit that took place in November 2021. During this summit, Biden and Xi discussed China’s domestic policies, trade relationships, and security issues regarding the Asian region (Politico). For this assignment, we used the R alongside a Quantenda package to scrape and analyze Twitter data on the day of the summit. The twitter data analyzed displayed activity ranging from interactions, trending hashtags, popular users that were tagged, and p\nrominent rhetoric on the day of the summit.\nThis is the summary of data:\nThe most popular hashtags on that were” #china”,” #joebiden”,” #xinjinping”, and “#america”. Other popular hashtags were “#usa,” “#breakingnews,” and “pray4america.” Quantenda data also pulled other popular hashtags from twitters among the ones not notes above are: “#uyghurgenocide,” “#uyghur,” “#humanrights,” “tibetans,” “taiwan,” “#coronavirus,” and interestingly enough “#fentanyl.” This plot shows how the variety of hashtags were used, and their connection with one another.\n\n\n\n\n\nThe Quantenda data allowed us to look at the 20 top users that were featured on the data matrix. The five top users mentioned were @POTUS, @JoeBiden, @Politico @EnesKanter, and @jendeben. The accompanying plot displays the interaction between various twitter users.\n\n\n\n\n\n\n\n\n\n\nAnother data point was analyzing lexical dispersion of US Presidents from 1953 to 2021. This plot ranged from 1953 when president Eisenhower was in office to current president Joe Biden. There is a lexical dispersion plot aimed to account for the frequency of times that presidents have used the term ‘american,’ in their speeches. In the plots this accounted for by referring to the term ‘relative token index.’ There is a wide variation of frequency among the US presidents, but according to the plot the use of the term does seem to slight increase around 1993 when Clinton was in office.\n\n\n\n\n\nThe second part of the lexical dispersion plot was comparing the frequencies between the words “american,” and “people.” The word “people,” showed less variation among presidents and was used quite frequently among all of them.\n\n\n\n\n\nLastly, we were asked to discuss Wordfish it. Wordfish analyzes positions of documents based on word frequencies. They do so by using a one-dimension scaling model."
  },
  {
    "objectID": "assign02.html#assignment-2-gtrends",
    "href": "assign02.html#assignment-2-gtrends",
    "title": "assign02",
    "section": "",
    "text": "I examined that number of searches for ‘Trump’ following the announcement of his election on June 6th 2015 for the 2016 US Election, up until 2023. I also examined the searches for ‘Biden’ following the same dates as my previous search.\nIn October and November 2016 there was a spike in searches for ‘Trump,’ coinciding to the election date. There was another sharp peak in ‘Trump,’ searches in October and November 2020. The search item ‘Biden’ was at its peak between the years of 2015 and 2023 in November 2020 during the election. Following the November 2020 election there was still more searches for ‘Biden,’ compared years 2015-early 2019, but not as frequent as the years of 2019 and 2020. The term ‘Election’ has a varied number of searches over time. The highest peaks being November 2016 and November 2020. There was a sharp dip of searches after January 2021, with some peaks in the searches in early to mid 2023.\nAll of the searches were exclusive to Google trends in the United States."
  },
  {
    "objectID": "assign06.html",
    "href": "assign06.html",
    "title": "assign06",
    "section": "",
    "text": "For this project we webscapred Martin Luther King’s “I Have A Dream Speech,” using a text mining script. The text mining scipt downloads the “htmlTreeParse” function which allows to break down the article and ultimately process different vectors like punctuation, paragraphs, and word-frequency; which I’ll talk about a little bit later.\nOnce we install the necessary packages like XML, wordcloud, RColorBrwer, NLP, tm, and quantenda, we process the speech as an html document. This makes it easier to sparse through. As seen in the image below, the speech is now processed as an html document on RStudio.\n\n\n\n\n\nFollowing this procedure we start vectorizing the words in the document and we then run the words.corpus too. Both the words.vec and words.corpus are seen in the data section of RStudio, and reveal the language, content, length, as well as other features in MLK’s speech.\n\n\n\n\n\nWe run other elements of words.corpus like removing punctuating and numbers to make it easier to analyze the text. Running TermDocumentMatrix, processes minuscule elements of the speech like integers and characters, this tool is helpful for the generation of wordcloud later. After the intial run of TermDocumentMatrix we can no analyze more broader parts of the text like word count, which can be seen in the picture below.\n\n\n\n\n\nWe can finally generate a wordcloud of MLK’s “I Have A Dream,” speech, that displays the most frequent words used.\n\n\n\n\n\nDr. Ho, then showed me how to play around with word frequencies. We were able to generate a wordcloud with words that were only mentioned once in the speech. As seen, the wordcloud becomes much more diverse."
  },
  {
    "objectID": "assign06.html#assignment-6-webscrapingtextmining",
    "href": "assign06.html#assignment-6-webscrapingtextmining",
    "title": "assign06",
    "section": "",
    "text": "For this project we webscapred Martin Luther King’s “I Have A Dream Speech,” using a text mining script. The text mining scipt downloads the “htmlTreeParse” function which allows to break down the article and ultimately process different vectors like punctuation, paragraphs, and word-frequency; which I’ll talk about a little bit later.\nOnce we install the necessary packages like XML, wordcloud, RColorBrwer, NLP, tm, and quantenda, we process the speech as an html document. This makes it easier to sparse through. As seen in the image below, the speech is now processed as an html document on RStudio.\n\n\n\n\n\nFollowing this procedure we start vectorizing the words in the document and we then run the words.corpus too. Both the words.vec and words.corpus are seen in the data section of RStudio, and reveal the language, content, length, as well as other features in MLK’s speech.\n\n\n\n\n\nWe run other elements of words.corpus like removing punctuating and numbers to make it easier to analyze the text. Running TermDocumentMatrix, processes minuscule elements of the speech like integers and characters, this tool is helpful for the generation of wordcloud later. After the intial run of TermDocumentMatrix we can no analyze more broader parts of the text like word count, which can be seen in the picture below.\n\n\n\n\n\nWe can finally generate a wordcloud of MLK’s “I Have A Dream,” speech, that displays the most frequent words used.\n\n\n\n\n\nDr. Ho, then showed me how to play around with word frequencies. We were able to generate a wordcloud with words that were only mentioned once in the speech. As seen, the wordcloud becomes much more diverse."
  },
  {
    "objectID": "assign01.html#assignment-1-surveys",
    "href": "assign01.html#assignment-1-surveys",
    "title": "assign01",
    "section": "",
    "text": "Analysis of survey:\nQ2a. The survey is structured in a way where questions concerning the content is presented before the demographic information is asked.\nQ2b. The questionnaire is composed of an array of different questions, that range from binary answers like yes or no to Likert scales questions. The survey also includes questions that have logic, this always questions to be followed up or skipped based on questions with binary responses.\nQ2c. The questions are ordered so that the survey questions are presented first and the demographics are placed last.\nQ7. One way to improve a respondent’s experience is to break up the survey into sections to maintain cohesion and synchronicity throughout the survey."
  }
]