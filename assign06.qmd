---
title: "assign06"
---

## Assignment 6: Webscraping/textmining

For this project we webscapred Martin Luther King's "I Have A Dream Speech," using a text mining script. The text mining scipt downloads the "htmlTreeParse" function which allows to break down the article and ultimately process different vectors like punctuation, paragraphs, and word-frequency; which I will discuss later.

Once we install the necessary packages like XML, wordcloud, RColorBrwer, NLP, tm, and quantenda, we process the speech as an html document. This makes it easier to sparse through. As seen in the image below, the speech is now processed as an html document on RStudio.

![](/images/paragraph-01.png){fig-align="center" width="561"}

Following this procedure we start vectorizing the words in the document and we then run the words.corpus too. Both the words.vec and words.corpus are seen in the data section of RStudio, and reveal the language, content, length, as well as other features in MLK's speech.

![](/images/Screenshot%20(136)-01.png){fig-align="center" width="484"}

We run other elements of words.corpus like removing punctuating and numbers to make it easier to analyze the text. Running TermDocumentMatrix, processes minuscule elements of the speech like integers and characters, this tool is helpful for the generation of wordcloud later. After the intial run of TermDocumentMatrix we can no analyze more broader parts of the text like word count, which can be seen in the picture below.

![](/images/wordcount1-01.png){fig-align="center" width="466"}

We can finally generate a wordcloud of MLK's "I Have A Dream," speech, that displays the most frequent words used.

![](/images/0364c463-2a56-458e-80d6-7fe21265513a-01.png){fig-align="center" width="563"}

Dr. Ho, then showed me how to play around with word frequencies. We were able to generate a wordcloud with words that were only mentioned once in the speech. As seen, the wordcloud becomes much more diverse.

![](/images/3c46bf3b-a45c-4e64-9dfd-4dffd209d727-01.png){fig-align="center" width="605"}

For the second part of the project we were expected to follow the same code for Winston Churchill's "The Finest Hour." After processing the speech as html document. We were able to vectorize different aspects of the speech. This was the TermDocumentMatrix for the Finest Hours:

![](images/Screenshot%20(143).png){width="520"}

This is the word cloud generated for words with a frequency of 10. Similar to the MLK portion, I played around with the frequencies and inputted 5 instead of 10, and saw a significant difference. Both wordclouds can be seen below.

![](images/wwc10){fig-align="center" width="416"}

![](images/wc5){fig-align="center" width="550"}
